{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045bb004",
   "metadata": {},
   "source": [
    "# Claris: Histopathology Cancer Detector\n",
    "\n",
    "This project was realized for Expo-Science hosted by Hydro-Quebec.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Many healthcare professionals are under great pressure with the current situation of Quebec's healthcare industry. A severe lack of personnel is a prominent issue, and the efficiency in cancer diagnosis process was worsened by this problem. It is not always easy to detect cancer in images. This project aims to develop a deep learning model that can detect histopathologic cancer in images, in order to ease the process of detection and pressure on the healthcare industry.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "https://www.kaggle.com/competitions/histopathologic-cancer-detection/data \n",
    "\n",
    "This dataset of histopathologic scans of lymph node sections is a modified version of the PCAM (PatchCamelyon) dataset.\n",
    "\n",
    "> \n",
    "    The PatchCamelyon benchmark (PCAM) consists of 327.680 color images (96 x 96px) extracted from histopathologic scans of lymph node sections. Each image is annoted with a binary label indicating presence of metastatic tissue.\n",
    "    Fundamental machine learning advancements are predominantly evaluated on straight-forward natural-image classification datasets and medical imaging is becoming one of the major applications of ML and thus deserves a spot on the list of go-to ML datasets. Both to challenge future work, and to steer developments into directions that are beneficial for this domain.\n",
    "\n",
    "\n",
    "## Model\n",
    "\n",
    "The model used in this project is DenseNet-121, a type of Convolutional Neural Network (CNN) for precision purposes. The CNN is trained on the dataset using the categorical cross-entropy loss function. The model will be able to classify the images into one of the following categories: benign or malignant.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "The implementation of the model is done with Jupyter Notebook using the Pytorch library. The model is trained on Kaggle duo-T4 GPU using the Adam optimizer. \n",
    "  \n",
    "## Accuracy\n",
    "The model achieved a peak accuracy of around 97.5% after 6 epochs.\n",
    "\n",
    "![alt text](image.png)\n",
    "\n",
    "## Sources\n",
    "Thanks to many Kaggle competitions, datasets and notebooks for inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751c685b",
   "metadata": {},
   "source": [
    "### 1) Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ddf5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4367266",
   "metadata": {},
   "source": [
    "#### Setting up the environment\n",
    "Using Kaggle's Nvidia GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24ededf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device -> Nvidia GPU\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Use GPU cuda if available\n",
    "print('Using device:', DEVICE)\n",
    "\n",
    "# Config\n",
    "IMG_SIZE = 96\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc0f8c",
   "metadata": {},
   "source": [
    "### 2) Data transformations\n",
    "Diversify the training data by augmenting the images with random rotations, flips, and translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89398910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data transformations\n",
    "#  - Augmented to increase diversity of the dataset\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),            # Ensure consistent size\n",
    "    transforms.RandomHorizontalFlip(),                  # Random flips (augmentation)\n",
    "    transforms.RandomVerticalFlip(),                    # Random flips  (augmentation)\n",
    "    transforms.RandomRotation(20),                      # Random rotations (augmentation)\n",
    "    transforms.ToTensor(),                              # Convert to tensor\n",
    "    transforms.Normalize(                               # Standardize pixel values\n",
    "        mean=[0.485, 0.456, 0.406],  # ImageNet mean\n",
    "        std=[0.229, 0.224, 0.225]    # ImageNet std\n",
    "    )\n",
    "])\n",
    "\n",
    "# Test data transformations (no augmentation or randomness)\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8868d4dd",
   "metadata": {},
   "source": [
    "### 3) Data loading helper class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95d3a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for Kaggle Histopathologic Cancer Detection (based on PCAM)\n",
    "    Uses .tif images + train_labels.csv\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, csv_path, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "        self.df = pd.read_csv(csv_path) # train_labels.csv\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.iloc[idx, 0]          # image id\n",
    "        label  = int(self.df.iloc[idx, 1])     # 0 or 1 (cancer or not)\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, img_id + \".tif\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b462615",
   "metadata": {},
   "source": [
    "### 4) Load PCam dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93081d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle directory (PCam)\n",
    "BASE_DIR = \"/kaggle/input/competitions/histopathologic-cancer-detection/\"\n",
    "\n",
    "TRAIN_DIR = BASE_DIR + \"train\"\n",
    "CSV_PATH = BASE_DIR + \"train_labels.csv\"\n",
    "\n",
    "# Train / validation test split\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Split into train and validation datasets\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df.to_csv(\"train_split.csv\", index=False)\n",
    "val_df.to_csv(\"val_split.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf43ea",
   "metadata": {},
   "source": [
    "#### Data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15054bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    TRAIN_DIR, \"train_split.csv\", train_tfms\n",
    ")\n",
    "\n",
    "val_dataset = Dataset(\n",
    "    TRAIN_DIR, \"val_split.csv\", val_tfms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True, # faster GPU data transfer\n",
    "    persistent_workers=True, # keep warm state for >1 epoch\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04848d87",
   "metadata": {},
   "source": [
    "### 5) Loading DenseNet-121 model\n",
    "The model has been pre-trained on ImageNet. <br>\n",
    "Hence, the model already knows how to detect edges, textures, patterns, colors, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68ce1871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained DenseNet121 from torchvision\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Replace the classifier layer\n",
    "# DenseNet outputs 1024 features â†’ we need 2 classes\n",
    "model.classifier = nn.Linear(1024, 2)\n",
    "\n",
    "# Wrap for multi-GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = torch.nn.DataParallel(model) # parallel computing\n",
    "    \n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480df87f",
   "metadata": {},
   "source": [
    "#### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbeb0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class imbalance handling\n",
    "class_weights = torch.tensor([1.0, 1.5]).to(DEVICE)\n",
    "\n",
    "# Binary classification\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Prevent underflow (~0 gradient rounded to 0)\n",
    "scaler = torch.amp.GradScaler() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d14be49",
   "metadata": {},
   "source": [
    "### 6) Training the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4577bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader):\n",
    "    model.train()  # training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    loop = tqdm(train_loader, total=len(train_loader))\n",
    "\n",
    "    for images, labels in loader:\n",
    "        # Move data to device (GPU)\n",
    "        images = images.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision training for faster training\n",
    "        # COMPARE RESULTS AND PENALIZE LOSS\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            # Forward pass (prediction results)\n",
    "            outputs = model(images)\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation (how should each weight change to make the loss smaller?)\n",
    "        scaler.scale(loss).backward() # loss.backward()\n",
    "\n",
    "        # Update weights for real\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loop.set_postfix(loss=running_loss / (loop.n+1))\n",
    "\n",
    "    return running_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b505f",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37b4fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader):\n",
    "    model.eval()  # evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\", leave=False): # Progress bar\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8dca1",
   "metadata": {},
   "source": [
    "### 7) Visualizing prediction results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b677acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1376 [09:28<?, ?it/s, loss=289] \n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 0.2099 | Val Acc: 95.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1376 [09:23<?, ?it/s, loss=195]  \n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Train Loss: 0.1420 | Val Acc: 96.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1376 [09:25<?, ?it/s, loss=169]  \n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Train Loss: 0.1227 | Val Acc: 96.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1376 [09:25<?, ?it/s, loss=145]  \n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Train Loss: 0.1056 | Val Acc: 97.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1376 [09:23<?, ?it/s, loss=132]  \n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Train Loss: 0.0958 | Val Acc: 96.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1376 [09:30<?, ?it/s, loss=120]   \n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] Train Loss: 0.0872 | Val Acc: 97.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1376 [09:25<?, ?it/s, loss=109]  \n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] Train Loss: 0.0795 | Val Acc: 97.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1376 [09:23<?, ?it/s, loss=101]   \n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] Train Loss: 0.0734 | Val Acc: 97.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1376 [09:30<?, ?it/s, loss=93.9] \n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] Train Loss: 0.0682 | Val Acc: 97.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1376 [09:29<?, ?it/s, loss=87.7]  \n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] Train Loss: 0.0637 | Val Acc: 97.42%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10  # increase later\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(model, train_loader)\n",
    "    val_acc = validate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Acc: {val_acc*100:.2f}%\")\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), \"pcam_model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
